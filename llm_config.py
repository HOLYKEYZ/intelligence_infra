LLM_CONFIG = {
    "model": "gpt-4.1-mini",
    "temperature": 0.2,
    "max_tokens": 512
}
